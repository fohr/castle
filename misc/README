TESTS-random_btree_get.patch
===
Test runs as a kthread that starts at module load, kicks off gets after ~10s.
Perform random point gets on the highest-level tree in DA.
You'll need to define:
    TESTS_RANDOM_BTREE_GET_NUM_KEYS - number of sequential keys you inserted in the DA
    TESTS_RANDOM_BTREE_GET_DA_ID - the DA ID
Expects single-dimensional keys so run perf_replace with --no-thread-safe-keys and --key-type ascending, e.g.:
    perf_replace --iterations 1 --batch-size 10000000 --key-type ascending --value-size 4 --async --reuse-buffer-count 128 --no-thread-safe-keys --output /dev/null


BTREE-read_null_backend.patch
===
Makes castle_btree_read_process() return INVAL_VAL_TUP for all requests.
__castle_btree_submit() may still do IO but this should still be minimal.
Useful for testing interface performance.
Consider running perf_get with --no-check-errors, e.g. /opt/acunu/tests/fs-tests.hg/perf_get --collection 0x0 --key-type ascending --value-size 4 --iterations 1 --batch-size 999999999 --reuse-buffer-count 2048 --output /dev/null --no-check-errors


INTERFACE-fastpath_requests.fs.hg.patch
INTERFACE-fastpath_requests.libcastle.hg.patch
===
Implements an ioctl()-based interface for puts that avoids using the shared ring.
No other special changes required.


keys_normalized_stress_test.c
===
Stress tests the packing / unpacking functions of normalized keys, in
order to hopefully catch bugs which only creep up in minority corner
cases etc. Change the testing parameters by modifying the MIN / MAX
constants at the beginning of the file.


keys_normalized_max_size.c
===
Given the maximum size of the VLBA keys passed from userspace,
calculates the maximum size of the resulting normalized keys. Needs to
be forward-ported / rerun every time the size limit or the normalized
keys implementation changes.

IKG.patch
===
In-kernel replace generator. Inserts are fired via the clone ioctl (hijacked for our nefarious performance testing purposes). With some manual tweaking it's possible to set this up to bypass or go through the back queue (by using castle_back_request_process, or going directly to castle_back_replace). Furthermore, it's possible to play with batching effects by changing the loop count in castle_in_kernel_replace.
